import requests
from bs4 import BeautifulSoup
import json
import urllib3
import time

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


def parse_electronics():
    # 1. –î–û–ë–ê–í–¨–¢–ï –°–Æ–î–ê –í–°–ï –°–°–´–õ–ö–ò, –ö–û–¢–û–†–´–ï –•–û–¢–ò–¢–ï –°–ü–ê–†–°–ò–¢–¨
    urls = [
        "https://5element.by/catalog/377-smartfony/brand=samsung",
        "https://5element.by/catalog/377-smartfony/iphone-17",
        "https://5element.by/products/iphone-16",
        "https://5element.by/catalog/1403-televizory/brand=samsung"
    ]

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    }

    all_products = []
    global_id = 3000  # –ù–∞—á–∞–ª—å–Ω—ã–π ID –¥–ª—è –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤

    for url in urls:
        print(f"üîé –°–∫–∞–Ω–∏—Ä—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            response = requests.get(url, headers=headers, verify=False, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ (–≤–∞—à –∫–ª–∞—Å—Å)
            items = soup.find_all(class_='c-list__item')
            print(f"   –ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(items)}")

            for item in items:
                try:
                    # –ù–∞–∑–≤–∞–Ω–∏–µ
                    title_el = item.find(class_='c-list__title')
                    if not title_el: continue
                    title = title_el.text.strip()

                    # –¶–µ–Ω–∞
                    price_el = item.find(class_='c-price__current') or item.find(class_='price')
                    price_text = price_el.text.strip() if price_el else "0"
                    price = int(''.join(filter(str.isdigit, price_text)))

                    # –ö–∞—Ä—Ç–∏–Ω–∫–∞
                    img_el = item.find('img')
                    img_url = img_el.get('data-src') or img_el.get('src') if img_el else ""

                    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    all_products.append({
                        "id": global_id,
                        "brand": "–¢–µ—Ö–Ω–∏–∫–∞",  # –ú–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –±—Ä–µ–Ω–¥–∞
                        "title": title,
                        "discount_price": price,
                        "image": img_url,
                        "description": f"–ö—É–ø–∏—Ç—å {title}. –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—è.",
                        "category": 1,
                        "in_stock": True
                    })
                    global_id += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º ID –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–≤–∞—Ä–∞
                except:
                    continue

            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã —Å–∞–π—Ç –Ω–∞—Å –Ω–µ –∑–∞–±–∞–Ω–∏–ª
            time.sleep(1)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Å—ã–ª–∫–µ {url}: {e}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
    with open('scraped_products.json', 'w', encoding='utf-8') as f:
        json.dump(all_products, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ –ì–û–¢–û–í–û! –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤.")
    print("–î–∞–Ω–Ω—ã–µ –≤ —Ñ–∞–π–ª–µ scraped_products.json")


if __name__ == "__main__":
    parse_electronics()